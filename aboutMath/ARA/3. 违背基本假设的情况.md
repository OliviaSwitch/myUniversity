在回归模型基本假设中有Gauss-Markov条件
![GaussMarkov](1.%20一元线性回归.md#^GaussM)

但实际中建立模型时常常存在与假设违背的情况：
1. 异方差性：$var(\varepsilon_{i})\ne var(\varepsilon_{j}),\ i\ne j$
2. 自相关性：$cov(\varepsilon_{i},\varepsilon_{j})\ne 0,\ i\ne j$

# 异方差性

## 异方差性产生的背景和原因

### 异方差性带来的问题

当存在异方差时，普通最小二乘估计存在以下问题：
1. 参数估计值虽是无偏的，但不是最小方差线性无偏估计； 
2. 参数的显著性检验失效； 
3. 回归方程的应用效果极不理想。

## 一元加权最小二乘估计

### 异方差性的检验

#### 残差图分析法

课本p39 图2-5中，图a，残差图中的n个点的散布呈随机，无规律，即为同方差；图b，残差e值随x值的增大而增大，具有明显的规律，可以认为误差项的方差是非齐性的，即为异方差。

```R
data4.3<-read.csv("data4.3.csv",head=TRUE)
lm4.3<-lm(y~x,data=data4.3) #建立回归方程 
summary(lm4.3)
e<-resid(lm4.3) #计算残差 
attach(data4.3) #将该数据框添加到 R 的搜索路径 
plot(x,e,ylim=c(-500,500)) #画散点图，ylim用于调整纵坐标的范围 
abline(h=c(0),lty=5) #添加虚直线 e=0 
detach(data4.3) #与 attach()相对应，将数据框从搜索路径中移除
```

#### 等级相关系数法(斯皮尔曼(Spearman)检验)

步骤：
1. 做$y$关于$x$的普通最小二乘回归，求出的$\varepsilon_{i}$估计值，即$e_{i}$的值
2. 取$\lvert e_{i} \rvert$，分别把$x_{i}$和$\lvert e_{i} \rvert$按递增或递减的次序排列后分成等级，按下式计算出等级相关系数
   $$
r_{s}=1-\frac{6}{n(n^{2}-1)}\sum\limits_{i=1}^nd_{i}^{2}
$$
其中，$n$为样本量，$d_{i}$为对应于$x_{i}$和$\lvert e_{i} \rvert$的等级差数
3. 做等级相关系数的显著性检验。在$n>8$的情况下，用下式对样本等级相关系数$r_{s}$进行$t$检验，检验统计量为
   $$
t=\frac{\sqrt{ n-2 }r_{s}}{\sqrt{ 1-r_{s}^{2} }}
$$
如果$\lvert t \rvert\le t_{\frac{\alpha}{2}}(n-2)$，可以认为异方差性问题不存在；如果$\lvert t \rvert> t_{\frac{\alpha}{2}}(n-2)$，说明与之间存在系统关系，异方差性问题存在。

```R
abse<-abs(e) #计算残差 e 的绝对
cor.test(data4.3$x,abse,alternative="two.sided“,method="spearman")
```

从以上结果可以看到（课本p95），等级相关系数$r_{s}=0.6858871$，$P$值$=3.316e-05$，认为残差绝对值$|e_{i}|$与自变量$x_{i}$显著相关，存在异方差。

### 一元加权最小二乘估计

消除异方差性的方法通常有：
- 加权最小二乘法 
- Box-Cox变换法 
- 方差稳定性变换法

加权最小二乘法(Weighted Least Square，WLS) 是一种最常用的消除异方差性的方法。

对于一元线性回归方程来说，普通最小二乘法的离差平方和为：
$$
\begin{aligned}
Q(\beta_{0},\beta_{1})&=\sum\limits_{i=1}^n(y_{i}-E(y_{i}))^{2}\\
&=\sum\limits_{i=1}^n(y_{i}-\beta_{0}-\beta_{1}x_{i})^{2}
\end{aligned}
$$
一元线性回归的加权最小二乘的离差平方和为：
$$
\begin{aligned}
Q_{w}(\beta_{0},\beta_{1})&=\sum\limits_{i=1}^nw_{i}(y_{i}-E(y_{i}))^{2}\\
&=\sum\limits_{i=1}^nw_{i}(y_{i}-\beta_{0}-\beta_{1}x_{i})^{2}
\end{aligned}
$$

加权最小二乘估计为：
$$
\begin{cases}
\hat{\beta}_{0w}  & =\bar{y}_{w}-\hat{\beta}_{1w}\bar{x}_{w} \\
\hat{\beta}_{1w}  & =\frac{\sum\limits_{i=1}^nw_{i}(x_{i}-\bar{x}_{w})(y_{i}-\bar{y}_{w})}{\sum\limits_{i=1}^nw_{i}(x_{i}-\bar{x}_{w})^{2}}
\end{cases}
$$

其中，$\bar{x}_{w}=\frac{1}{\sum w_{i}}\sum w_{i}x_{i}$是自变量的加权平均；$\bar{x}_{w}=\frac{1}{\sum w_{i}}\sum w_{i}y_{i}$$是因变量的加权平均

为了消除异方差的影响，观测值的权数应该是观测值 误差项方差的倒数，即
$$
w_{i}=\frac{1}{\sigma_{i}^{2}}
$$
所以误差项的方差较大的观测值接受较小的权数；误差项的方差较小的观测值接受较大的权数。

在实际问题中，误差项的方差是未知的，常与自变量$x$的幂函数$x^m$成比例，其中$m$是待定的未知参数。此时权函数为
$$
w_{i}=\frac{1}{x_{i}^m}
$$

^7f1fd4

### 寻找最优权函数

利用 R 软件可以确定式[4.6](#^7f1fd4)幂指数$m$的最优取值，一般情况下，幂指数的取值为$-2.0, -1.5, -1.0, -0.5, 0, 0.5, 1.5, 2.0$，可以根据实际情况进行调整。
寻找最优的权函数，即为确定$m$的取值，使回归方程最优。
此处我们以对数似然统计量作为衡量回归方程优劣的标准，计算不同的$m$值对应的对数似然值，取使其最大者。

```R
s<-seq(-2,2,0.5) #生成序列-2.0， -1.5， -1.0， …， 1.5,2.0 
result1 <- vector(length = 9, mode = "list") 
#生成一个列表向量，以存储下面循环过程中的回归方程估计的对数 似然统计量结果 
result2 <- vector(length = 9, mode = "list") 
#生成一个列表向量，以存储下面循环过程中所建立回归方程的估计系数及显著性检验等结果 

for (j in 1:9) {
	w<-data4.3$x^(-s[j]) #计算权向量 
	lm4<-lm(y~x,weights=w,data4.3)#使用加权最小二乘法建立回归方程 
	result1[[j]]<-logLik(lm4) #将第 j 次计算的对数似然统计量保存在 result1 的第 j 个元素中 
	result2[[j]]<-summary(lm4)#将 j 次建立的回归方程的结果保存在 result2 的第 j 个元素中 
} 
result1 #输出所有的对数似然统计量
```

从结果中可看出第8个对数似然估计的值是最大的，对应的m=1.5。

`result2[[8]]` 输出result2中保存的第8个回归模型的结果，可看到R2 = 0.935 9， F值 = 423.7；而普通最小二乘估计的 R2 = 0.912， F值 = 300.7。这说明加权最小二乘估计的效果好于普通最小二乘估计的效果

绘制加权最小二乘法的残差图
```R
lm4.3w=result2[[8]] 
ew=resid(lm4.3w);
plot(data4.3$x,ew,ylim=c(-0.1,0.1))     #画散点图，ylim用于调整纵坐标的范围
abline(h=c(0),lty=5)     #添加虚直线 e=0
```

比较[普通残差图](#残差图分析法)和加权最小二乘残差图， 我们可能看不出两张图之间的差异。这是否表明加权最小二乘回归没有达到效果？

经过书本p100的分析，可以得出以下结论：
- 回归模型存在异方差时，加权最小二乘估计只是对普通最小二乘的改进，这种改进可能是细微的，不能理解为加权最小二乘估计一定会得到与普通最小二乘估计截然不同的回归方程，或者一定有大幅度的改进。
	- 加权最小二乘以牺牲大方差项的拟合效果为代价改善了小方差项的拟合效果，这也并不总是研究者需要的。在社会经济现象中，通常变量取值大时方差也大，在以经济总量为研究目标时，更关心变量取值大的项，而普通最小二乘恰好能满足这个要求。所以在这样的一些特定场合下，即使数据存在异方差，也仍然可以选择使用普通最小二乘估计。

## 多元加权最小二乘估计

### 多元加权最小二乘估计 

对于一般的多元线性回归模型，当误差项$\varepsilon_{i}$存在异方 差时，加权离差平方和为
$$
Q_{w}=\sum\limits_{i=1}^nw_{i}(y_{i}-\beta_{0}-\beta_{1}x_{i2}-\beta_{2}x_{i2}-\cdots-\beta_{p}x_{ip})^{2}
$$
易得加权最小二乘估计（WLSE）的矩阵表达式
$$
\hat{\boldsymbol{\beta}}_{w}=(\boldsymbol{X^{\prime} WX})^{-1}\boldsymbol{X^{\prime}Wy }
$$
其中
$$W=\begin{vmatrix}
w_{1} &  &  &  & \vdots\\ 
 & w_{2} &  &  &  \\
 &  & \ddots &  &  \\
\vdots &  &  &  & w_{n}
\end{vmatrix}$$

### 权函数的确定方法

通常取权函数$W$为某个自变量$x_j(j=1,2,\cdots p)$的幂函数，即 $W=x_{j}^m$。那么在$x_1 ,x_2 ,\cdots ,x_p$这$p$个自变量中应该取哪一个？这只需计算每个自变量$x_j$与普通残差的等级相关系 数，选取等级相关系数最大的自变量构造权函数。

具体见课本例4-4

# 自相关性

## 自相关性问题及其处理

如果一个回归模型的随机误差项
$$
cov(\varepsilon_{i},\varepsilon_{j})\ne0,\quad i,j=1,2,\cdots ,n)
$$
则称随机误差项之间存在着自相关现象。

这里的自相关现象不是指两个或两个以上的变量之间的相关，而指的是一个变量前后期数值之间存在的相关关系。

### 自相关性产生的背景和原因

1. 遗漏关键变量时会产生序列的自相关性 
2. 经济变量的滞后性会给序列带来自相关性 
3. 采用错误的回归函数形式也可能引起自相关性 
4. 蛛网现象(Cobweb phenomenon)可能带来序列的自相关性 
5. 因对数据加工整理而导致误差项之间产生自相关性

### 自相关性带来的问题

1. 参数的估计值不再具有最小方差线性无偏性 
2. 均方误差MSE可能严重低估误差项的方差 
3. 容易导致对t值评价过高，常用的F检验和t检验失效 
4. 当存在序列相关时， 仍然是β的无偏估计量，但在任一特定的样本中，可能严重歪曲β的真实情况，即最小二乘估计量对抽样波动变得非常敏感 
5. 如果不加处理地运用普通最小二乘法估计模型参数，用此模型进行预测和结构分析将会带来较大的方差甚至错误的解释。

###  自相关性的诊断

#### 图示检验法

图示检验法是一种直观的诊断方法，它是对给定的回归模型直接用普通的最小二乘法估计参数，求出残差项$e_{t},e_{i}$作为随机项$\varepsilon_{t}$的真实值的估计值，再描绘$e_{t}$的散点图，根据$e_{t}$的相关性来判断随机项$\varepsilon_{t}$的序列相关性。

残差$e_{t}$的散点图通常有两种绘制方式：
1. 绘制$(e_t，e_{t-1})$的散点图。用$(e_{t-1},e_{t}(t=2,3,\cdots ,n))$作为散布点绘图。
   如果大部分点落在第1,3象限，表明随机扰动项$e_{t}$存在正的序列相关，如p106图4-3(a)；
   如果大部分点落在第2,4象限，表明随机扰动项$e_{t}$存在负的序列相关，如p106图4-3(b) 
2. 按照时间顺序绘制回归残差项$e_t$的图形。如果$e_{t}(t=1,2,\cdots ,n)$随着$t$的变化逐次有规律地呈现锯齿状或循环形状的变化，就可断言$e_{t}$存在相关，表明$\varepsilon_{t}$存在序列相关。
   
#### 自相关系数法

误差序列$\varepsilon_1 ,\varepsilon_2 ,\cdots ,\varepsilon_{n}$的自相关系数定义为
$$
\rho=\frac{\sum\limits_{t=2}^n\varepsilon_{t}\varepsilon_{t-1}}{\sqrt{ \sum\limits_{t=2}^n\varepsilon_{t}^{2}}\sqrt{ \sum\limits_{t=2}^n\varepsilon_{t-1}^2 }}
$$
自相关系数$\rho \in [-1,1]$，当$\rho$接近1，表明误差序列存在正相关；当$\rho$接近-1，表明误差序列存在负相关。

自相关系数的估计值为
$$
\hat{\rho}=\frac{\sum\limits_{t=2}^n e_{t}e_{t-1}}{\sqrt{ \sum\limits_{t=2}^ne_{t}^{2}}\sqrt{ \sum\limits_{t=2}^ne_{t-1}^2 }}
$$

$\hat{\rho}$作为自相关系数的估计值与样本量有关，需要做统计显著性建议才能确定自相关性是否存在，通常采用[DW检验](#DW检验)代替对$\hat{\rho}$的检验

#### DW检验

DW检验是J.Durbin和G.S.Watson于1951年提出的一种适用于小样本的一种检验方法。DW检验只能用于检验随机扰动项具有一阶自回归形式的序列相关问题。

随机扰动项的一阶自回归形式为
$$
\varepsilon_{t}=\rho\varepsilon_{t-1}+u_{t}
$$
其中$u_{t}$是不相关序列。

为了检验序列的相关性，构造的假设：
$$
H_{0}:\rho=0
$$

定义DW统计量为
$$
\begin{align}
DW & =\frac{\sum\limits_{t=2}^n(e_{t}-e_{t-1})^{2}}{\sum\limits_{t=2}^ne_{i}^{2}}  \\
 & =\frac{\sum\limits_{t=2}^ne_{t}^{2}+\sum\limits_{t=2}^ne_{t-1}^{2}-2\sum\limits_{t=2}^ne_{t}e_{t-1}}{\sum\limits_{t=2}^ne_{t}^{2}} \\
 & \approx 2\left( 1-\frac{\sum\limits_{t=2}^ne_{t}e_{t-1}}{\sum\limits_{t=2}^ne_{i}^{2}} \right)
\end{align}
$$

又$\hat{\rho}=\frac{\sum\limits_{t=2}^n e_{t}e_{t-1}}{\sqrt{ \sum\limits_{t=2}^ne_{t}^{2}}\sqrt{ \sum\limits_{t=2}^ne_{t-1}^2 }}=\approx\frac{\sum\limits_{t=2}^ne_{t}e_{t-1}}{\sum\limits_{t=2}^ne_{t}^{2}}$

可以得到 $DW\approx 2(1-\hat{\rho}), DW\in[0,4]$

在认为$\sum\limits_{t=2}^ne_{t}^{2}\approx \sum\limits_{t=2}^ne_{t-1}^{2}$时，可以得到以上近似关系。

DW值与$\hat{\rho}$的对应关系

| $\hat{\rho}$ | DW    | 误差项的自相关性 |
| ------------ | ----- | ---------------- |
| -1           | 4     | 完全负自相关     |
| (-1,0)       | (2,4) | 负自相关         |
| 0            | 2     | 无自相关         |
| (0,1)        | (0,2) | 正自相关         |
| 1            | 0     | 完全正自相关                 |

根据样本容量$n$和解释变量的数目$k$（这里包括常数项），查DW分布表，得临界值$d_L$和$d_U$，然后依下列准则考察计算得到的DW值，以确定模型的自相关状态。

| $0 \le DW\le d_L$       | 误差项$\varepsilon_1 ,\varepsilon_2 ,\cdots,\varepsilon_n$间存在正相关 |
| --------------- | ------------------------------ |
| $d_L＜DW\le d_U$      | 不能判定是否有自相关           |
| $d_U＜DW＜ 4-d_U$   | 误差项$\varepsilon_1 ,\varepsilon_2 ,\cdots,\varepsilon_n$间无自相关   |
| $4-d_U \le DW＜ 4-d_L$ | 不能判定是否有自相关           |
| $4-d_L \le DW\le 4$     | 误差项$\varepsilon_1 ,\varepsilon_2 ,\cdots,\varepsilon_n$间存在负相关                               |

(需要查表，具体见课本)

##### DW检验的缺点和局限性

1. DW检验有一个不能确定的区域，一旦DW值落在这个区域，就无法判断，这时只有增大样本容量或选取其他方法。 
2. DW统计量的上、下界表要求n＞15，这是因为样 本如果再小利用残差就很难对自相关的存在性做出比较正确的诊断。 
3. DW检验不适应随机项具有高阶序列相关的检验。
   
##### 代码

```R
> install.packages("lmtest")# 安装
> library(lmtest)# 导入包
> dwtest(lm4.13,alternative='two.sided') #DW检验
	Durbin-Watson test

data:  lm4.13
DW = 0.66325, p-value = 0.0001257
alternative hypothesis: true autocorrelation is not 0

# 可知DW值为0.663，P值=0.0001257，查DW表，n=20,k=2,显著性水平α=0.05，
# 得dL=1.20,dU=1.41,由于DW=0.663<dL=1.20,知DW值落入正相关区域，即残差序列存在正的自相关。
```

### 自相关问题的处理方法

#### 迭代法

以一元线性回归模型为例，设一元线性回归模型的误差项存在一阶自相关
$$
y_{t}=\beta_{0}+\beta_{1}x_{t}+\varepsilon_{t}
$$
$$
\varepsilon_{t}=\rho\varepsilon_{t-1}+u_{t}
$$
$$
\begin{cases}
E(u_{t})=0,t=1,2,\cdots ,n \\
cov(u_{t},u_{s})=\begin{cases}
\sigma^{2},&t=s \\
0,&t\ne s
\end{cases}\quad (t,s=1,2,\cdots ,n)
\end{cases}
$$

那么，根据模型式，有
$$
y_{t-1}=\beta_{0}+\beta_{1}x_{t-1}+\varepsilon_{t-1}
$$
两端同时乘$\rho$，并被模型式减后得到
$$
(y_{t}-\rho y_{t-1})=(\beta_{0}-\rho \beta_{0})+\beta_{1}(x_{t}-\rho x_{t-1})+(\varepsilon_{t}-\rho\varepsilon_{t-1})
$$

令
$$
\begin{align}
y_{t}^{\prime}  & =y_{t}-\rho y_{t-1} \\
x_{t}^{\prime}  & =x_{t}-\rho x_{t-1}
\end{align}
$$
$$
\beta_{0}^{\prime} =\beta_{0}(1-\rho), \beta_{1}^{\prime} =\beta_{1}
$$
得到模型式
$$
y_{t}^{\prime} =\beta_{0}^{\prime}+\beta_{1}^{\prime}x_{t}^{\prime}+u_{t}$$

有不相关的误差项，但该式中$\rho$未知。

自相关系数$\rho$用公式$\hat{\rho} \approx 1-\frac{1}{2}DW$估计，然后用变换因变量与变换自变量作普通最小二乘回归。
如果误差项确实是一阶自相关，通过以上变换，回归模型已经消除自相关。
实际问题中，有时误差项并不是简单的一阶自相关，而是更复杂的自相关形式。此时需要对变换后得到的回归模型的残差做DW检验，如果误差项仍存在自相关，需要继续重复使用迭代法，直至最终消除误差项自相关。这种通过迭代消除自相关的过程正是迭代法名称的由来。

##### 迭代法的代码实现

依照式$y_{t}^{\prime} =\beta_{0}^{\prime}+\beta_{1}^{\prime}x_{t}^{\prime}+u_{t}$计算变换因变量$y_t^{\prime}$与变换自变量 $x_t^{\prime}$ ，结果如表4-6所示（见课本111页）。然后用$y_t^{\prime}$对$x_t^{\prime}$作普通最小二乘回归，计算结果见输出结果4.6（见下页），残差$e_t^{\prime}$列在表4-6中。从输出结果4.6中看到，新回归残差$e_t^{\prime}$的DW = 1.8204，P=0.5043，在0.05的显著性水平下，不拒绝原假设，认为误差项不存在自相关。误差项ut的标准差 ，小于$\varepsilon_t$的标准差 。$y_t^{\prime}$对$x_t^{\prime}$的回归方程为
$$y_t^{\prime}=185.337+0.628x_t^{\prime}$$
还原为原始变量的方程为
$$
\hat{y} = 185.337 0.8585y_{t-1} + 0.628x_t+ 0.53918x_{t-1}
$$

#### 差分法

比迭代法稍简单点。一阶差分法通常适用于原模型存在较高程度的一阶自相关的情况。

在迭代法的式子
$$
(y_{t}-\rho y_{t-1})=(\beta_{0}-\rho \beta_{0})+\beta_{1}(x_{t}-\rho x_{t-1})+(\varepsilon_{t}-\rho\varepsilon_{t-1})
$$
中，当$\rho=1$时，得到
$$
(y_{t}-y_{t-1})=\beta_{1}(x_{t}-x_{t-1})+(\varepsilon_{t}-\varepsilon_{t-1})
$$
用$\Delta y_{t}=y_{t}-y_{t-1},\Delta x_{t}=x_{t}-x_{t-1}$代之，得
$$
\Delta y_{t}=\beta_{1}\Delta x_{t}+u_{t}
$$
该式不存在序列的自相关，它是以差分数据$\Delta y_{t},\Delta x_{t}$为样本的回归方程。

用最小二乘法，得
$$
\hat{\beta}_{1}=\frac{\sum\limits_{t=2}^n\Delta y_{t}\Delta x_{t}}{\sum\limits_{t=2}^n\Delta x_{t}^{2}}
$$

一阶差分法的应用条件是自相关系数$\rho=1$，在实际应用中，$\rho$接近1时我们就采用差分法而不用迭代法，这有两个原因：
1. 迭代法需要用样本估计自相关系数$\rho$，对$\rho$的估计误差会影响迭代法的使用效率 
2. 差分法比迭代法简单，人们在建立时序数据的回归模型时，更习惯于用差分法。 

但是，完全的$\rho=1$情况几乎是见不到的，实际应用时$\rho$较大即可

##### 差分法的代码实现

首先计算差分$\Delta y_t=y_t-y_t-1，\Delta x_t=x_t-x_t-1$，差分结果列在表4-7中然后用$\Delta y_t$对$\Delta x_t$做过原点的最小二乘回归，计算结果见输出结果4.7（见下页），其中残差$e_t^{\prime}$列在表4-7中。从输出结果4.7中看到，新回归残差$e_t^{\prime}$的DW = 1.4148，P=0.156 9，在显著性水平为0.05时认为不存在自相关。误差项$u_t$的标准差 ，小于$εt$的标准差211.071。 $\Delta y_t$对$\Delta x_t$的回归方程为：$$\Delta y_t=0.637\Delta x_t$$ 将$\Delta y_t=y_t-y_t-1，\Delta x_t=x_t-x_t-1$代入，还原为原始变量的方程$$y_t=y_t-1+0.637(x_t-x_t-1) $$

### 预测

## BOX-COX变换

它对因变量$y$做如下变化$$
\begin{cases}
y^{(\lambda)}=\frac{y^{\lambda}-1}{\lambda}& \lambda\neq 0\\
y^{(\lambda)}=\ln y & \lambda=0
\end{cases}
$$

找到合适的 $\lambda$，使得变换后$$
y^{(\lambda)}=(y_1^{(\lambda)},y_2^{(\lambda)},\cdots,y_n^{(\lambda)})^{\prime}\sim N_n(\boldsymbol{X\beta},\sigma^2\boldsymbol{I})$$ 经过计算可得$\lambda$的最大似然估计 $$
L_{\max}(\lambda)=(2\pi e\hat{\sigma}^2_{\lambda})^{-2/n}|J|
$$ 式中，$\hat{\sigma}^2_{\lambda}=\frac{1}{n}SSE(\lambda,y^{\lambda}),|J|=\prod^n_{i=1}\left|\frac{dy^{\lambda}_i}{dy_i}\right|=\prod^n_{i=1}y^{\lambda-1}_i$

令$z^{\lambda}=\frac{y^{\lambda}}{|J|}$，对$L_{\max}(\lambda)$取对数并略去与$\lambda$无关的常数项，可得$$
\ln L_{\max}(\lambda)=-\frac{n}{2}\ln SSE(\lambda,z{(\lambda)})$$

#### 代码实现

在R中，可调用 `MASS` 包中的 `boxcox()` 函数，计算出
一系列$\lambda$对应的对数似然函数值$\ln L_{\max}(\lambda)$ ，其中使对数似然函数值达到最大的$\lambda$即为需要的$\lambda$值

##### 1. 消除异方差

首先，使用R中`boxcox()`函数寻找使对数似然函数$\ln L_{\max}(\lambda)$取得最大值的$\lambda$。然后，对$y$做变换，对变换后的$y$关于$x_1$和$x_2$做线性回归

```R
library(MASS) #加载 MASS 包
bc3.2<-boxcox(y~x1+x2,data = data3.2,lambda = seq(-2,2,0.01)) #lambda 的取值为区间[-2,2]上步长为 0.01 的值， bc3.2 中保存了 λ 的值和对应的对数似然函数值
lambda<-bc3.2$x[which.max(bc3.2$y)]
lambda
y_bc<-(data3.2$y^lambda-1)/lambda #计算变换后的 y 值
lm3.2_bc<-lm(y_bc~x1+x2,data = data3.2) #使用变换后的 y 值建立回归方程
summary(lm3.2_bc)
abse<-abs(resid(lm3.2_bc)) #计算残差的绝对值
cor.test(data3.2$x1,abse,method = "spearman") #计算残差与 x1 的相关系数
cor.test(data3.2$x2,abse,method = “spearman”) #计算残差与 x2 的相关系数
```

根据输出结果，使似然函数取值最大的 $\lambda=0.47$，变换后的$\hat{y}^{(0.47)}$对$x_1,x2$的回归方程为$$
\hat{y}^{(0.47)}=6.80+0.05x_1+0.014x_2
$$
还原为原始变量的方程为$\hat{y}=(4.196+0.024x_1+0.007x_2)^{1/0.47}$

由输出结果可看到，残差绝对值与$x_1$和$x_2$的等级相关系数t检验的P值分别为 0.0623，0.3401，在显著性水平为0.05 时都不显著，故可认为异方差被消除。
另外，经过 BOX-COX变换后的$R^2=0.845$， F值=32.72；而普通最小二乘的$R^2=0.842$，F 值=31.96；加权最小二乘的$R^2=0.849$，F值=33.84。这说明用BOX-COX变换和加权最小二乘估计都能消除异方差，但对于本例的数据用加权最小二乘的拟合效果要略好

##### 2. 消除自相关

使用BOX-COX变换以消除残差序列自相关

```R
bc2.2<-boxcox(y~x,data = data2.2,lambda = seq(-2,2,0.01))
# λ 的取值为区间[-2,2]上步长为 0.01 的值
lambda<-bc2.2$x[which.max(bc2.2$y)]
y_bc<-(data2.2$y^lambda-1)/lambda
summary(lm2.2_bc<-lm(y_bc~x,data = data2.2))
lambda
```

(see ppt)

## 异常值与强影响点

异常值分为两种情况：
- 一种是关于因变量y异常；
- 另一种是关于自变量x异常。

